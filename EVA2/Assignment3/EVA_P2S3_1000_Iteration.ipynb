{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA P2S3 - 1000 Iteration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roulupen/EVAAssignments/blob/master/EVA2/Assignment3/EVA_P2S3_1000_Iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHBHiGL2NBXc",
        "colab_type": "code",
        "outputId": "7dcc0d02-31dc-4ed8-9a9a-78a7b18461ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/roulupen/EVAAssignments.git"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'EVAAssignments' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA",
        "colab_type": "text"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = open('./EVAAssignments/EVA2/Assignment3/text.txt', 'r').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb",
        "colab_type": "text"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab_type": "code",
        "outputId": "ec753bc4-f96b-42a1-eb30-19c7cd9d474f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY",
        "colab_type": "text"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Hidden_Layer_size = 10 #size of the hidden layer\n",
        "Time_steps = 10 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb",
        "colab_type": "text"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "    return y * (1-y)\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "    return 1-y**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-",
        "colab_type": "text"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z25en6PuSGQa",
        "colab_type": "code",
        "outputId": "7915dcca-f6ee-4103-e330-f3f4dfaa56f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5xbTDVISQBn",
        "colab_type": "code",
        "outputId": "0bd7b5bf-0b6f-48f0-bada-572de37c0e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOY-nsAYSfeU",
        "colab_type": "code",
        "outputId": "feb8fe7e-14ac-445c-c3a4-3738d799a2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdxut-JWSnLX",
        "colab_type": "code",
        "outputId": "aabe558c-c10b-4fb0-ebdb-1c1a46819368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE",
        "colab_type": "text"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212",
        "colab_type": "text"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V",
        "colab_type": "text"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5",
        "colab_type": "text"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size_a = Hidden_Layer_size\n",
        "size_b = z_size\n",
        "size_c = X_size\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v, self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs",
        "colab_type": "text"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid( np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid( np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh( np.dot(p.W_C.v, z)+ p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid( np.dot(p.W_o.v, z) + p.b_i.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI",
        "colab_type": "text"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG--0rjFoYrg",
        "colab_type": "code",
        "outputId": "ce1d83d2-3d63-44c7-b73f-23fa6289d2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8",
        "colab_type": "text"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHqvt_Lo3orv",
        "colab_type": "code",
        "outputId": "fc4828c7-ed7b-4e8b-f3fe-261b6ba171f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 1)\n",
            "0.0\n",
            "5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG",
        "colab_type": "text"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S",
        "colab_type": "text"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA",
        "colab_type": "text"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y",
        "colab_type": "text"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV",
        "colab_type": "text"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L",
        "colab_type": "text"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a",
        "colab_type": "text"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK",
        "colab_type": "text"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab_type": "code",
        "outputId": "5449243e-abf9-4bc5-c2e6-bd18dbd8f445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "iter = 1000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD1CAYAAACWXdT/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgiCsAAk1gRBEBaAxJogCMIC/D825lGz702ULwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " eviannltitidn luEs anas thcamtase Saoniree ive cane aureS.ir te haiti, an, enbbicat Chiuud tuolod inthoshbtongvar  on are. 0selit,tlt sh a tiats thoth Cpn'graletye'vpond.\n",
            " wlon ing5 de ,a) thimen a at \n",
            "----\n",
            "iter 1900, loss 28.264588\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}